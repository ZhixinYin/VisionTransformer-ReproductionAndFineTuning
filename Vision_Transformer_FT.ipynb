{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/tiny-imagenet-200\"\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "images_dir = os.path.join(val_dir, \"images\")\n",
        "ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
        "\n",
        "# Read annotations\n",
        "with open(ann_file) as f:\n",
        "    annotations = [line.strip().split('\\t') for line in f]\n",
        "\n",
        "# Create class folders and move images\n",
        "for img, cls, *_ in annotations:\n",
        "    cls_dir = os.path.join(val_dir, cls)\n",
        "    os.makedirs(cls_dir, exist_ok=True)\n",
        "    shutil.move(\n",
        "        os.path.join(images_dir, img),\n",
        "        os.path.join(cls_dir, img)\n",
        "    )\n",
        "\n",
        "os.rmdir(images_dir)"
      ],
      "metadata": {
        "id": "sBpfogDFFtTD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "!pip -q install tf-keras"
      ],
      "metadata": {
        "id": "VHGEDpxzLY6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers"
      ],
      "metadata": {
        "id": "mMz309tsFqau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training set\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/tiny-imagenet-200/train\",\n",
        "    image_size=(256, 256),\n",
        "    batch_size=None,\n",
        "    label_mode=\"int\"\n",
        ")\n",
        "\n",
        "# load test set\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/tiny-imagenet-200/val\",\n",
        "    image_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    label_mode=\"int\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWXt-2ywFvEs",
        "outputId": "e81929d6-cb89-405a-d681-d98d2f288577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 files belonging to 200 classes.\n",
            "Found 10000 files belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(image):\n",
        "  image = tf.image.random_crop(image, (224, 224, 3))\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image"
      ],
      "metadata": {
        "id": "QGTEFAvSF0ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(lambda x, y: (random_crop(x), y))\n",
        "train_ds = train_ds.batch(64)"
      ],
      "metadata": {
        "id": "stqEKrTXF25v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalisation(images):\n",
        "  mean = tf.constant([0.5, 0.5, 0.5])\n",
        "  std = tf.constant([0.5, 0.5, 0.5])\n",
        "  return (images / 255.0 - mean) / std"
      ],
      "metadata": {
        "id": "AfG2xdqEF4ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(lambda x, y: (normalisation(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalisation(x), y))"
      ],
      "metadata": {
        "id": "PEbGff8GF6ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tonchw(image, label):\n",
        "  return tf.transpose(image, [0, 3, 1, 2]), label"
      ],
      "metadata": {
        "id": "UgTdOY2xMbr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(tonchw)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(tonchw)\n",
        "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "KgvhlWdpMzfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sct-4_PJEhLq",
        "outputId": "4b93c284-7c18-4591-eb21-2583ca69c9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All PyTorch model weights were used when initializing TFViTModel.\n",
            "\n",
            "All the weights of TFViTModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFViTModel\n",
        "\n",
        "vit = TFViTModel.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    from_pt=True,\n",
        "    use_safetensors=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(3, 224, 224))\n",
        "\n",
        "outputs = vit(inputs, training=True)\n",
        "cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "x = layers.Dropout(0.1)(cls_token)\n",
        "x = layers.Dense(200)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, x)"
      ],
      "metadata": {
        "id": "0CSrsK0_GdKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(train_ds, epochs=5)"
      ],
      "metadata": {
        "id": "o4aJKZI9JWQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6046186d-46c4-419b-8972-21eaa2740741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 580s 363ms/step - loss: 1.3280 - accuracy: 0.8003\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 568s 363ms/step - loss: 0.6213 - accuracy: 0.8518\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 568s 363ms/step - loss: 0.5504 - accuracy: 0.8633\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 568s 363ms/step - loss: 0.5033 - accuracy: 0.8709\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 568s 363ms/step - loss: 0.4677 - accuracy: 0.8787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7b27ebd2cd10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(train_ds, epochs=20)"
      ],
      "metadata": {
        "id": "x9lL4Zd4JkWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc5d207-0150-4a5a-c11a-42aabd9a1958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 1614s 1s/step - loss: 0.3473 - accuracy: 0.9070\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.2485 - accuracy: 0.9315\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.1883 - accuracy: 0.9485\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.1470 - accuracy: 0.9600\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.1109 - accuracy: 0.9709\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0854 - accuracy: 0.9787\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0648 - accuracy: 0.9848\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0506 - accuracy: 0.9888\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0404 - accuracy: 0.9914\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0309 - accuracy: 0.9936\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 1565s 1s/step - loss: 0.0259 - accuracy: 0.9947\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 1565s 1s/step - loss: 0.0222 - accuracy: 0.9954\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0170 - accuracy: 0.9968\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0151 - accuracy: 0.9969\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0127 - accuracy: 0.9977\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0132 - accuracy: 0.9970\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 1565s 1s/step - loss: 0.0101 - accuracy: 0.9977\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 1565s 1s/step - loss: 0.0081 - accuracy: 0.9984\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 1566s 1s/step - loss: 0.0102 - accuracy: 0.9976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7b27e3f0b680>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "0dGf4Y9WJzXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07cc7be-d418-4851-bb2b-74133d1ad3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 60s 363ms/step - loss: 0.5162 - accuracy: 0.8987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5162237882614136, 0.8986999988555908]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}